
/* WebCL Validator JSON header
{
    "version" : "1.0",
    "kernels" :
        {
            "histogram256" :
                {
                    "d_PartialHistograms" :
                        {
                            "index" : 0,
                            "type" : "uint *",
                            "address-space" : "global",
                            "size-parameter" : "_wcl_d_PartialHistograms_size"
                        },
                    "_wcl_d_PartialHistograms_size" :
                        {
                            "index" : 1,
                            "type" : "ulong"
                        },
                    "d_Data" :
                        {
                            "index" : 2,
                            "type" : "uint *",
                            "address-space" : "global",
                            "size-parameter" : "_wcl_d_Data_size"
                        },
                    "_wcl_d_Data_size" :
                        {
                            "index" : 3,
                            "type" : "ulong"
                        },
                    "dataCount" :
                        {
                            "index" : 4,
                            "type" : "uint"
                        }
                },
            "mergeHistogram256" :
                {
                    "d_Histogram" :
                        {
                            "index" : 0,
                            "type" : "uint *",
                            "address-space" : "global",
                            "size-parameter" : "_wcl_d_Histogram_size"
                        },
                    "_wcl_d_Histogram_size" :
                        {
                            "index" : 1,
                            "type" : "ulong"
                        },
                    "d_PartialHistograms" :
                        {
                            "index" : 2,
                            "type" : "uint *",
                            "address-space" : "global",
                            "size-parameter" : "_wcl_d_PartialHistograms_size"
                        },
                    "_wcl_d_PartialHistograms_size" :
                        {
                            "index" : 3,
                            "type" : "ulong"
                        },
                    "histogramCount" :
                        {
                            "index" : 4,
                            "type" : "uint"
                        }
                }
        }
}
*/

// WebCL Validator: validation stage.
#define _WCL_ADDRESS_SPACE_private_MIN (((8 + (CHAR_BIT - 1)) / CHAR_BIT))
#define _WCL_ADDRESS_SPACE_private_ALIGNMENT (8/CHAR_BIT)
#define _WCL_ADDRESS_SPACE_global_MIN (((32 + (CHAR_BIT - 1)) / CHAR_BIT))
#define _WCL_ADDRESS_SPACE_global_ALIGNMENT (32/CHAR_BIT)
#define _WCL_ADDRESS_SPACE_local_MIN (((32 + (CHAR_BIT - 1)) / CHAR_BIT))
#define _WCL_ADDRESS_SPACE_local_ALIGNMENT (32/CHAR_BIT)
#define _WCL_ADDRESS_SPACE_constant_MIN (((8 + (CHAR_BIT - 1)) / CHAR_BIT))
#define _WCL_ADDRESS_SPACE_constant_ALIGNMENT (8/CHAR_BIT)
typedef struct {
    uint _wcl_count;
    __local uint *_wcl_l_WarpHist;
} __attribute__ ((aligned (_WCL_ADDRESS_SPACE_private_ALIGNMENT))) _WclPrivates;

typedef struct {
    uint _wcl_l_Hist[1536];
    uint _wcl_l_Data[256];
} __attribute__ ((aligned (_WCL_ADDRESS_SPACE_local_ALIGNMENT))) _WclLocals;

typedef struct {
    __global uint *histogram256__d_PartialHistograms_min;
    __global uint *histogram256__d_PartialHistograms_max;
    __global uint *histogram256__d_Data_min;
    __global uint *histogram256__d_Data_max;
    __global uint *mergeHistogram256__d_Histogram_min;
    __global uint *mergeHistogram256__d_Histogram_max;
    __global uint *mergeHistogram256__d_PartialHistograms_min;
    __global uint *mergeHistogram256__d_PartialHistograms_max;
} _WclGlobalLimits;

typedef struct {
    __local _WclLocals * _wcl_locals_min;
    __local _WclLocals * _wcl_locals_max;
} _WclLocalLimits;

typedef struct {
    _WclGlobalLimits gl;
    __global uint *gn;
    _WclLocalLimits ll;
    __local uint *ln;
    _WclPrivates pa;
    __private uint *pn;
} _WclProgramAllocations;

__constant uint _wcl_constant_null[_WCL_ADDRESS_SPACE_constant_MIN] = { 0 };

// => General code that doesn't depend on input.

#define _WCL_MEMCPY(dst, src) for(ulong i = 0; i < sizeof((src))/sizeof((src)[0]); i++) { (dst)[i] = (src)[i]; }

#define _WCL_LAST(type, ptr) (((type)(ptr)) - 1)
#define _WCL_FILLCHAR ((uchar)0xCC)

// POCL crashes at run time if the parameters are local character
// pointers.
typedef uint _WclInitType;

// NOTE: this expects that null pointer is type of uint*
#define _WCL_SET_NULL(type, req_bytes, min, max, null) ( ((((type)max)-((type)min))*sizeof(uint) >= req_bytes) ? ((type)min) : (null) )

#ifdef cl_khr_initialize_memory
#pragma OPENCL EXTENSION cl_khr_initialize_memory : enable
#define _WCL_LOCAL_RANGE_INIT(begin, end)
#else

// be careful to edit this, this has been carefully tuned to work on every OpenCL driver
// e.g. % item_count was added to start[(items_offset+i)] = _WCL_FILLCHAR;
// to prevent compiler crash on Apple GeForce 640M
#define _WCL_LOCAL_RANGE_INIT(begin, end) do {               \
    __local uchar *start = (__local uchar *)begin;           \
    __local uchar *stop = (__local uchar *)end;              \
    const size_t z_items = get_local_size(2);                \
    const size_t yz_items = get_local_size(1) * z_items;     \
    const size_t xyz_items = get_local_size(0) * yz_items;   \
    const size_t item_index =                                \
        (get_local_id(0) * yz_items) +                       \
        (get_local_id(1) * z_items) +                        \
        get_local_id(2);                                     \
    size_t item_count = stop - start;                        \
    size_t items_per_kernel = item_count / xyz_items;        \
    size_t items_offset = items_per_kernel * item_index;     \
    size_t reminders = item_count % xyz_items;               \
    if (item_index < reminders) {                            \
        start[xyz_items*items_per_kernel + item_index] = _WCL_FILLCHAR; \
    }                                                                   \
    for (size_t i = 0; i < items_per_kernel; i++) {                     \
        start[(items_offset+i) % item_count] = _WCL_FILLCHAR;           \
    }                                                                   \
} while (0)                                                             \

#endif // cl_khr_initialize_memory

// <= General code that doesn't depend on input.

bool _wcl_addr_check_global_4__u_uglobal__uint__Ptr(__global uint *addr, unsigned size, __global uint * min0, __global uint * max0, __global uint * min1, __global uint * max1, __global uint * min2, __global uint * max2, __global uint * min3, __global uint * max3)
{
      return 0
        || ( ((addr) >= (min0)) && ((addr + size - 1) <= _WCL_LAST(__global uint *, max0)) )
        || ( ((addr) >= (min1)) && ((addr + size - 1) <= _WCL_LAST(__global uint *, max1)) )
        || ( ((addr) >= (min2)) && ((addr + size - 1) <= _WCL_LAST(__global uint *, max2)) )
        || ( ((addr) >= (min3)) && ((addr + size - 1) <= _WCL_LAST(__global uint *, max3)) );
}
__global uint *_wcl_addr_clamp_global_4__u_uglobal__uint__Ptr(__global uint *addr, unsigned size, __global uint * min0, __global uint * max0, __global uint * min1, __global uint * max1, __global uint * min2, __global uint * max2, __global uint * min3, __global uint * max3, __global uint * asnull)
{
     return _wcl_addr_check_global_4__u_uglobal__uint__Ptr(addr, size, min0, max0, min1, max1, min2, max2, min3, max3) ? addr : asnull;
}

bool _wcl_addr_check_local_1__u_ulocal__uint__Ptr(__local uint *addr, unsigned size, __local uint * min0, __local uint * max0)
{
      return 0
        || ( ((addr) >= (min0)) && ((addr + size - 1) <= _WCL_LAST(__local uint *, max0)) );
}
__local uint *_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr(__local uint *addr, unsigned size, __local uint * min0, __local uint * max0, __local uint * asnull)
{
     return _wcl_addr_check_local_1__u_ulocal__uint__Ptr(addr, size, min0, max0) ? addr : asnull;
}

bool _wcl_addr_check_local_1_volatile___u_ulocal__uint__Ptr(volatile __local uint *addr, unsigned size, volatile __local uint * min0, volatile __local uint * max0)
{
      return 0
        || ( ((addr) >= (min0)) && ((addr + size - 1) <= _WCL_LAST(volatile __local uint *, max0)) );
}
volatile __local uint *_wcl_addr_clamp_local_1_volatile___u_ulocal__uint__Ptr(volatile __local uint *addr, unsigned size, volatile __local uint * min0, volatile __local uint * max0, volatile __local uint * asnull)
{
     return _wcl_addr_check_local_1_volatile___u_ulocal__uint__Ptr(addr, size, min0, max0) ? addr : asnull;
}


// WebCL Validator: matching stage 2.
// WebCL Validator: matching stage 1.
/*
 * Copyright 1993-2010 NVIDIA Corporation.  All rights reserved.
 *
 * Please refer to the NVIDIA end user license agreement (EULA) associated
 * with this source code for terms and conditions that govern your use of
 * this software. Any use, reproduction, disclosure, or distribution of
 * this software and related documentation outside the terms of the EULA
 * is strictly prohibited.
 *
 */



//Passed down by clBuildProgram
//#define LOG2_WARP_SIZE 5U
//#define     WARP_COUNT 6

////////////////////////////////////////////////////////////////////////////////
// Common definition
////////////////////////////////////////////////////////////////////////////////





//Workgroup size


//Local memory per workgroup




////////////////////////////////////////////////////////////////////////////////
// Main computation pass: compute per-workgroup partial histograms
////////////////////////////////////////////////////////////////////////////////


inline void addByte(_WclProgramAllocations *_wcl_allocs, volatile __local uint *l_WarpHist, uint data, uint tag){
    uint count;
    do{
        _wcl_allocs->pa._wcl_count = (*(_wcl_addr_clamp_local_1_volatile___u_ulocal__uint__Ptr((l_WarpHist)+(data), 1, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_min, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_max, (volatile __local uint *)_wcl_allocs->ln))) & ( (1U << (32U - 5)) - 1U );
        _wcl_allocs->pa._wcl_count = tag | (_wcl_allocs->pa._wcl_count + 1);
        (*(_wcl_addr_clamp_local_1_volatile___u_ulocal__uint__Ptr((l_WarpHist)+(data), 1, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_min, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_max, (volatile __local uint *)_wcl_allocs->ln))) = _wcl_allocs->pa._wcl_count;
    }while((*(_wcl_addr_clamp_local_1_volatile___u_ulocal__uint__Ptr((l_WarpHist)+(data), 1, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_min, (volatile __local uint *)_wcl_allocs->ll._wcl_locals_max, (volatile __local uint *)_wcl_allocs->ln))) != _wcl_allocs->pa._wcl_count);
}

inline void addWord(_WclProgramAllocations *_wcl_allocs, volatile __local uint *l_WarpHist, uint data, uint tag){
    addByte(_wcl_allocs, l_WarpHist, (data >> 0) & 0xFFU, tag);
    addByte(_wcl_allocs, l_WarpHist, (data >> 8) & 0xFFU, tag);
    addByte(_wcl_allocs, l_WarpHist, (data >> 16) & 0xFFU, tag);
    addByte(_wcl_allocs, l_WarpHist, (data >> 24) & 0xFFU, tag);
}

__kernel __attribute__((reqd_work_group_size((6 * (1U << 5)), 1, 1)))
void histogram256(
    __global uint *d_PartialHistograms, ulong _wcl_d_PartialHistograms_size,
    __global uint *d_Data, ulong _wcl_d_Data_size,
    uint dataCount
){

    __local _WclLocals _wcl_locals;
    __local uint _wcl_local_null[_WCL_ADDRESS_SPACE_local_MIN];

    _WclProgramAllocations _wcl_allocations_allocation = {
        { &d_PartialHistograms[0], &d_PartialHistograms[_wcl_d_PartialHistograms_size],&d_Data[0], &d_Data[_wcl_d_Data_size],0, 0,0, 0 },
        0,
        { &(&_wcl_locals)[0], &(&_wcl_locals)[1] },
        _wcl_local_null,
        { },
        0

    };
    _WclProgramAllocations *_wcl_allocs = &_wcl_allocations_allocation;
    _wcl_allocs->gn = _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.histogram256__d_PartialHistograms_min, _wcl_allocs->gl.histogram256__d_PartialHistograms_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.histogram256__d_Data_min, _wcl_allocs->gl.histogram256__d_Data_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, _wcl_allocs->gl.mergeHistogram256__d_Histogram_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, _wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint*)0))));
    if (_wcl_allocs->gn == (__global uint*)0) return; // not enough space to meet the minimum access. Would be great if we could give info about the problem for the user. 
    _wcl_allocs->pn = _WCL_SET_NULL(__private uint*, _WCL_ADDRESS_SPACE_private_MIN, &_wcl_allocs->pa, (&_wcl_allocs->pa + 1), (__private uint*)0);
    if (_wcl_allocs->pn == (__private uint*)0) return; // not enough space to meet the minimum access. Would be great if we could give info about the problem for the user. 

    // => Local memory zeroing.
    _WCL_LOCAL_RANGE_INIT(_wcl_allocs->ll._wcl_locals_min, _wcl_allocs->ll._wcl_locals_max);
    _WCL_LOCAL_RANGE_INIT(_wcl_local_null, _wcl_local_null + _WCL_ADDRESS_SPACE_local_MIN);
    barrier(CLK_LOCAL_MEM_FENCE);
    // <= Local memory zeroing.

    //Per-warp substorage storage
    __local uint l_Hist[6 * 256];
    __local uint *l_WarpHist = _wcl_locals._wcl_l_Hist + (get_local_id(0) >> 5) * 256;;_wcl_allocs->pa._wcl_l_WarpHist = l_WarpHist;

    //Clear shared memory storage for current threadblock before processing
    for(uint i = 0; i < (256 / (1U << 5)); i++)
        (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Hist)+(get_local_id(0) + i * (6 * (1U << 5))), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln))) = 0;

    const uint tag = get_local_id(0) << (32 - 5);

    //Read through the entire input buffer, build per-warp histograms
    barrier(CLK_LOCAL_MEM_FENCE);
    for(uint pos = get_global_id(0); pos < dataCount; pos += get_global_size(0)){
        uint data = (*(_wcl_addr_clamp_global_4__u_uglobal__uint__Ptr((d_Data)+(pos), 1, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_min, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gn)));
        addWord(_wcl_allocs, _wcl_allocs->pa._wcl_l_WarpHist, data, tag);
    }

    //Per-block histogram reduction
    barrier(CLK_LOCAL_MEM_FENCE);
    for(uint pos = get_local_id(0); pos < 256; pos += (6 * (1U << 5))){
        uint sum = 0;

        for(uint i = 0; i < 6; i++)
            sum += (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Hist)+(pos + i * 256), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln))) & ( (1U << (32U - 5)) - 1U );

        (*(_wcl_addr_clamp_global_4__u_uglobal__uint__Ptr((d_PartialHistograms)+(get_group_id(0) * 256 + pos), 1, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_min, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gn))) = sum;
    }
}



////////////////////////////////////////////////////////////////////////////////
// Merge histogram256() output
// Run one workgroup per bin; each workgroup adds up the same bin counter 
// from every partial histogram. Reads are uncoalesced, but mergeHistogram256
// takes only a fraction of total processing time
////////////////////////////////////////////////////////////////////////////////
//Passed down by clBuildProgram
//#define MERGE_WORKGROUP_SIZE 256

__kernel __attribute__((reqd_work_group_size(256, 1, 1)))
void mergeHistogram256(
    __global uint *d_Histogram, ulong _wcl_d_Histogram_size,
    __global uint *d_PartialHistograms, ulong _wcl_d_PartialHistograms_size,
    uint histogramCount
){

    __local _WclLocals _wcl_locals;
    __local uint _wcl_local_null[_WCL_ADDRESS_SPACE_local_MIN];

    _WclProgramAllocations _wcl_allocations_allocation = {
        { 0, 0,0, 0,&d_Histogram[0], &d_Histogram[_wcl_d_Histogram_size],&d_PartialHistograms[0], &d_PartialHistograms[_wcl_d_PartialHistograms_size] },
        0,
        { &(&_wcl_locals)[0], &(&_wcl_locals)[1] },
        _wcl_local_null,
        { },
        0

    };
    _WclProgramAllocations *_wcl_allocs = &_wcl_allocations_allocation;
    _wcl_allocs->gn = _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.histogram256__d_PartialHistograms_min, _wcl_allocs->gl.histogram256__d_PartialHistograms_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.histogram256__d_Data_min, _wcl_allocs->gl.histogram256__d_Data_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, _wcl_allocs->gl.mergeHistogram256__d_Histogram_max, _WCL_SET_NULL(__global uint*, _WCL_ADDRESS_SPACE_global_MIN,_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, _wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint*)0))));
    if (_wcl_allocs->gn == (__global uint*)0) return; // not enough space to meet the minimum access. Would be great if we could give info about the problem for the user. 
    _wcl_allocs->pn = _WCL_SET_NULL(__private uint*, _WCL_ADDRESS_SPACE_private_MIN, &_wcl_allocs->pa, (&_wcl_allocs->pa + 1), (__private uint*)0);
    if (_wcl_allocs->pn == (__private uint*)0) return; // not enough space to meet the minimum access. Would be great if we could give info about the problem for the user. 

    // => Local memory zeroing.
    _WCL_LOCAL_RANGE_INIT(_wcl_allocs->ll._wcl_locals_min, _wcl_allocs->ll._wcl_locals_max);
    _WCL_LOCAL_RANGE_INIT(_wcl_local_null, _wcl_local_null + _WCL_ADDRESS_SPACE_local_MIN);
    barrier(CLK_LOCAL_MEM_FENCE);
    // <= Local memory zeroing.

    __local uint l_Data[256];

    uint sum = 0;
    for(uint i = get_local_id(0); i < histogramCount; i += 256)
        sum += (*(_wcl_addr_clamp_global_4__u_uglobal__uint__Ptr((d_PartialHistograms)+(get_group_id(0) + i * 256), 1, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_min, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gn)));
    (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Data)+(get_local_id(0)), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln))) = sum;

    for(uint stride = 256 / 2; stride > 0; stride >>= 1){
        barrier(CLK_LOCAL_MEM_FENCE);
        if(get_local_id(0) < stride)
            (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Data)+(get_local_id(0)), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln))) += (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Data)+(get_local_id(0) + stride), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln)));
    }

    if(get_local_id(0) == 0)
        (*(_wcl_addr_clamp_global_4__u_uglobal__uint__Ptr((d_Histogram)+(get_group_id(0)), 1, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.histogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_min, (__global uint *)_wcl_allocs->gl.histogram256__d_Data_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_Histogram_max, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_min, (__global uint *)_wcl_allocs->gl.mergeHistogram256__d_PartialHistograms_max, (__global uint *)_wcl_allocs->gn))) = (*(_wcl_addr_clamp_local_1__u_ulocal__uint__Ptr((_wcl_locals._wcl_l_Data)+(0), 1, (__local uint *)_wcl_allocs->ll._wcl_locals_min, (__local uint *)_wcl_allocs->ll._wcl_locals_max, (__local uint *)_wcl_allocs->ln)));
}
